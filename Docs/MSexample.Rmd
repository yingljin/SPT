---
title: "Investigating MS Lesion Scans"
author: "Ying Jin"
date: "`r Sys.Date()`"
output: 
  html_document:
    self_contained: true
    number_sections: true
    code_folding: show
    toc: true
    toc_depth: 3
    toc_float: true
    font: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(neurobase) # https://cran.r-project.org/web/packages/neurobase/index.html
library(tidyverse)
library(here)
theme_set(theme_minimal())
```


```{r load_data}
# all
# load(here("DataOutput/df_scans.RData"))
load(here("DataOutput/registered.RData"))
```


```{r}

### File paths ####
# list.files("DataRaw")
paths <- read.csv(here("DataRaw/WM_lesion_QC_result.csv"))
# 82 scans
# 8 subjects
# 4 sites
# two scans each sites

#### Read processed image and segmentation ####
paths <- paths %>% 
  separate(., col=flair_files, 
           into = c(rep(NA, 8), "registration", "flair", "name1"),
           sep = "/") %>% 
  separate(., col=mimosa_files, 
           into = c(rep(NA, 8), "mimosa", "name2"),
           sep = "/") 

paths <- paths %>%
  mutate(subject = gsub("-", "", subject)) %>%
  mutate(
  file_path = paste0("DataRaw/processed/data/sub-", subject, "/ses-", session, 
                     "/whitestripe/FLAIR_space/t1_n4_brain_reg_flair_ws.nii.gz"),
  seg_path =  paste0("DataRaw/processed/data/sub-", subject, "/ses-", session, 
                     "/", mimosa, "/", name2)
) 

```



```{r}
# let's use one subject as an example 
paths_01001 <- paths %>% filter(subject=="01001") 

# reading in and display
list_mat <- list()
list_img <- list()
list_seg_img <- list()
list_seg_mat <- list()
for(p in seq_along(paths_01001$file_path)){
  
  # image
  img_p <- readNIfTI(here(paths_01001$file_path[p]), reorient = F)
  list_img[[p]] <- img_p
  list_mat[[p]] <- img_p@.Data
  # segmentation
  seg_p <- readNIfTI(here(paths_01001$seg_path[p]), reorient = F)
  list_seg_img[[p]] <- seg_p
  list_seg_mat[[p]] <- seg_p@.Data
}

# lapply(list_mat, dim)
```


# Data

The image data was read in as two 3-D matrices. The first one contains the intensity values, the second binary flags, with one indicating a lesion voxel and zero a normal voxel. Please note that the lesion flag was obtained through a automatic segmentation process. As a consequence, there could be false positive flags.

Below is an example of one subject (01-001). Voxels labeled as lesion are marked out by red. 


```{r BWH}
ortho2(x=list_img[[1]], y=list_seg_img[[1]], crosshair=FALSE,  
       text = paths_01001$session[1], 
       text.x=40, text.y = 10, text.cex = 1)
ortho2(x=list_img[[2]], y=list_seg_img[[2]], crosshair=FALSE,
       text = paths_01001$session[2], 
       text.x=40, text.y = 10, text.cex = 1)
```


```{r JHU}
ortho2(x=list_img[[3]], y=list_seg_img[[3]], crosshair=FALSE,  
       text = paths_01001$session[3], 
       text.x=40, text.y = 10, text.cex = 1)
ortho2(x=list_img[[4]], y=list_seg_img[[4]], crosshair=FALSE,
       text = paths_01001$session[4], 
       text.x=40, text.y = 10, text.cex = 1)
```


```{r NIH}
ortho2(x=list_img[[5]], y=list_seg_img[[5]], crosshair=FALSE,  
       text = paths_01001$session[5], 
       text.x=40, text.y = 10, text.cex = 1)
ortho2(x=list_img[[6]], y=list_seg_img[[6]], crosshair=FALSE,
       text = paths_01001$session[6], 
       text.x=40, text.y = 10, text.cex = 1)
```


```{r Penn}
ortho2(x=list_img[[7]], y=list_seg_img[[7]], crosshair=FALSE,  
       text = paths_01001$session[7], 
       text.x=40, text.y = 10, text.cex = 1)
ortho2(x=list_img[[8]], y=list_seg_img[[8]], crosshair=FALSE,
       text = paths_01001$session[8], 
       text.x=40, text.y = 10, text.cex = 1)
```







# Preliminary analysis 

The current plan is to study the correlation between scans done at each specific area. A separate linear regression model of scan 2 on scan 1 is fit on each subject at each site, and only voxels that are labeled as "positive" in both scans are used in the regression.   

Below is a detailed procedure for regression on each subject at each site:

1. pick out voxels that are labeled positive in both scan.
2. standardize the intensity value 
3. fit regression a model calculate pearson correlation between scans from the same subject at the same site

The major concern with this output is the lack of correlation across scans from the same subject at the same site. As the figure shows, the correlation value is very close two zero for most of these figures. 

I used the whitestripe/FLAIR_space/ti_n4_brain_reg_flair_ws.nii.gz in this analysis, which seems to be the final destination of all preprocessing procedure. Compared to the images in "registration", the correlation increased, but not by a lot. We also see some outlyint voxels. 

<!-- After learning that Quy did analysis on the whole brain -->

I want to try to do the analysis on the brain instead of the lesion, and see if that produce stronger correlation. It turns out the magnitude of correlation is not large (< 10%), but the correlation is very significant

If we could register scans from the same site, we may see higher correlation. I need to talk to Quy and Elizabeth to figure out how to do that. But the problem is, this data does not look like the data Amy's using. 

<!-- After reviewing Elizabeth's code -->
It looks like Elizabeth ignored the position correspondance, and sampled voxels from the large lesion to match the smaller lesion

```{r}
# subject and site
dataDir = '/Users/jinyin/Desktop/SPT/DataRaw/data'
subs = list.dirs(dataDir, full.names = F, recursive = F)
subs = subs[grepl("sub", subs)] # folder names of subjects

# list the sites for each subject
site = lapply(subs, function(sub) {
  list.dirs(paste0(dataDir, '/', sub), full.names = F, recursive = F)
})

# subset session 1
ses1 = lapply(site, function(s1) {
  s1[grepl("_01$", s1)]
})

# subset session 2
ses2 = lapply(site, function(s2) {
  s2[grepl("_02$", s2)]
})
```

```{r}
# combine the two data sets from visit 1 and 2
combined_results = lapply(seq_along(results_ses1), function(sub) {
  lapply(seq_along(results_ses1[[sub]]), function(ses) {
    
    # combine session 1 and session 2 data with an inner join  
    combined_data = results_ses1[[sub]][[ses]] %>% 
      inner_join(results_ses2[[sub]][[ses]], by = c("voxel", "x", "y", "z"), suffix = c("_1", "_2")) %>% 
    
      # standardize the flair and t1 intensities
      mutate(
        flair_intensity1_std = (flair_intensity1 - mean(flair_intensity1, na.rm = TRUE)) / sd(flair_intensity1, na.rm = TRUE),
        flair_intensity2_std = (flair_intensity2 - mean(flair_intensity2, na.rm = TRUE)) / sd(flair_intensity2, na.rm = TRUE),
        
        t1_intensity1_std = (t1_intensity1 - mean(t1_intensity1, na.rm = TRUE)) / sd(t1_intensity1, na.rm = TRUE),
        t1_intensity2_std = (t1_intensity2 - mean(t1_intensity2, na.rm = TRUE)) / sd(t1_intensity2, na.rm = TRUE)
      )
    
    return(combined_data)
  })
})
```

```{r}
# name the combined data
names(combined_results) <- subs
site_name <- lapply(ses1, function(ses){
  ses = gsub("ses-", "", ses)
  ses = gsub("_01", "", ses)
  return(ses)
})

for(site in seq_along(combined_results)){
  names(combined_results[[site]]) <- site_name[[site]]
  
}

# put into one big data frame
df_scan <- lapply(combined_results, bind_rows, .id = "site")
df_scan <- bind_rows(df_scan, .id = "sub")
```



Below is a display of the results. If any subject did not received a scan at any site, the corresponding figure is left empty. 


```{r fig.height=32, fig.width=12}
df_scan %>% 
  group_by(sub, site) %>%
  ggplot(aes(x=t1_intensity1, y=t1_intensity2))+
  geom_point(size = 0.2, na.rm = T, alpha = 0.5)+
  geom_smooth(formula = y~x, method = "lm", na.rm = T)+
  ggpubr::stat_cor(cor.coef.name = "R", na.rm = T)+
  facet_grid(rows = vars(sub), cols = vars(site))+
  labs(y="Scan 2", x="Scan 1", title = "T1")
```


```{r fig.height=32, fig.width=12}
df_scan %>% 
  group_by(sub, site) %>%
  ggplot(aes(x=flair_intensity1, y=flair_intensity2))+
  geom_point(size = 0.2, na.rm = T, alpha = 0.5)+
  geom_smooth(formula = y~x, method = "lm", na.rm = T)+
  ggpubr::stat_cor(cor.coef.name = "R", na.rm = T)+
  facet_grid(rows = vars(sub), cols = vars(site))+
  labs(y="Scan 2", x="Scan 1", title = "flair")
```





# Try GAN 

```{r}
library(RGAN)

# let's start with just on subject
df_01001 <- df_scan %>% filter(sub == "sub-01001"& site == "NIH")

plot(df_01001$t1_intensity1_std, df_01001$t1_intensity2_std, 
     cex = 0.5, pch = 16)

# Set the device you want to train on.
# First, we check whether a compatible GPU is available for computation.
use_cuda <- torch::cuda_is_available()

# If so we would use it to speed up training (especially for models with image data).
device <- ifelse(use_cuda, "cuda", "cpu")

# Now train the GAN and observe some intermediate results.
tic <- Sys.time()
res <-
  gan_trainer(
    df_01001 %>% select(t1_intensity1_std, t1_intensity2_std) %>% as.matrix(), 
    eval_dropout = TRUE,
    plot_progress = TRUE,
    plot_interval = 600,
    device = device
  )

toc <- Sys.time()

toc-tic
```